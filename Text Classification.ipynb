{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVSnYOuyYziQLyyWgS13cf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuxiufeng/Spam_ham_Classification/blob/main/Text%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unzip files"
      ],
      "metadata": {
        "id": "8L8B6jr5IyLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip enron1_test.zip\n",
        "!unzip enron1_train.zip\n",
        "!unzip enron4_test.zip\n",
        "!unzip enron4_train.zip\n",
        "!unzip hw1.zip # upload hw(including train and set) 1 to colab\n"
      ],
      "metadata": {
        "id": "lfIqbafV9oKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stop Words\n",
        "\n",
        "step words from the nltk library\n",
        "              "
      ],
      "metadata": {
        "id": "PcpZknSALn80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \n",
        "              \"you're\", \"you've\",\"you'll\", \"you'd\", 'your', 'yours', 'yourself', \n",
        "              'yourselves', 'he', 'him', 'his','himself', 'she', \"she's\", 'her', \n",
        "              'hers', 'herself', 'it', \"it's\", 'its', 'itself','they', 'them', \n",
        "              'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom',\n",
        "              'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', \n",
        "              'was', 'were', 'be','been', 'being', 'have', 'has', 'had', 'having', \n",
        "              'do', 'does', 'did', 'doing', 'a','an', 'the', 'and', 'but', 'if', \n",
        "              'or', 'because', 'as', 'until', 'while', 'of', 'at','by', 'for', \n",
        "              'with', 'about', 'against', 'between', 'into', 'through', 'during',\n",
        "              'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', \n",
        "              'out', 'on','off', 'over', 'under', 'again', 'further', 'then', 'once', \n",
        "              'here', 'there', 'when','where', 'why', 'how', 'all', 'any', 'both', \n",
        "              'each', 'few', 'more', 'most', 'other','some', 'such', 'no', 'nor', 'not', \n",
        "              'only', 'own', 'same', 'so', 'than', 'too', 'very','s', 't', 'can', 'will', \n",
        "              'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd','ll', 'm', 'o', 're', \n",
        "              've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", \n",
        "              'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\",\n",
        "              'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
        "              'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won',\n",
        "              \"won't\", 'wouldn', \"wouldn't\"]"
      ],
      "metadata": {
        "id": "iKNCrQbReRFU"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library"
      ],
      "metadata": {
        "id": "ZN34fl0ILsvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "import random\n",
        "import codecs\n",
        "import numpy as np\n",
        "from decimal import Decimal\n",
        "from math import log\n",
        "from collections import Counter\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "Q8ZJ_vkYci1k"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Data"
      ],
      "metadata": {
        "id": "lXBIW0SOMDIM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  path_of_dataset_name: The path of folder. For example, 'content/enron1'\n",
        "*  True_or_False_train_set: True means it is train set; otherwise, it is test set\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ivqBbRxYNfFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def import_data_train_or_test(path_of_dataset_name, True_or_False_train_set):\n",
        "    all_ham_emails_raw_content = []\n",
        "    all_spam_emails_raw_content = []\n",
        "    all_spam_ham_content = \"\"\n",
        "    if True_or_False_train_set == True:\n",
        "        path = path_of_dataset_name + '/train'\n",
        "    else:\n",
        "        path = path_of_dataset_name + '/test'\n",
        "    path_ham = path + '/ham/'\n",
        "    path_spam = path + '/spam/'\n",
        "    all_spam_emails_raw_contents_list = os.listdir(path_spam)\n",
        "    all_ham_emails_raw_contents_list = os.listdir(path_ham)\n",
        "    for all_spam_emails_raw_contents in all_spam_emails_raw_contents_list:\n",
        "      total_spam_path = path_spam + all_spam_emails_raw_contents\n",
        "      all_spam_emails_raw_content.append(open(total_spam_path, \"r\", errors = 'ignore').read())\n",
        "      all_spam_ham_content = all_spam_ham_content + \" \" + open(total_spam_path, \"r\", errors = 'ignore').read()\n",
        "    for all_ham_emails_raw_contents in all_ham_emails_raw_contents_list:\n",
        "      total_ham_path = path_ham + all_ham_emails_raw_contents\n",
        "      all_ham_emails_raw_content.append(open(total_ham_path, \"r\", errors = 'ignore').read())\n",
        "      all_spam_ham_content = all_spam_ham_content + \" \" + open(total_ham_path, \"r\", errors = 'ignore').read()\n",
        "    # we find the size of the dataset and the number of instances with spam and number of instances with ham\n",
        "    num_of_files_whole_dataset = len(all_ham_emails_raw_contents_list) + len(all_spam_emails_raw_contents_list)\n",
        "    num_of_files_ham_dataset = len(all_ham_emails_raw_contents_list)\n",
        "    num_of_files_spam_dataset = len(all_spam_emails_raw_contents_list)\n",
        "    return all_spam_emails_raw_content, all_ham_emails_raw_content, all_spam_ham_content, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset"
      ],
      "metadata": {
        "id": "xgbWpg_cQdOY"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bag of Words model"
      ],
      "metadata": {
        "id": "1Vi1s5pbgFql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  path_of_dataset_name: The path of folder. For example, 'content/enron1'\n",
        "*  True_or_False_train_set: True means it is train set; otherwise, it is test set"
      ],
      "metadata": {
        "id": "y937MugKUn_p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "UGpTiB3u9kmF"
      },
      "outputs": [],
      "source": [
        "def bag_of_words_model(path_of_dataset_name, True_or_False_train_set):\n",
        "    all_spam_emails_raw_content, all_ham_emails_raw_content, all_spam_ham_content, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset = import_data_train_or_test(path_of_dataset_name, True_or_False_train_set)\n",
        "    total_words_dictionary = {} # total words dictionary\n",
        "    total_file_words = re.findall(\"[a-zA-Z]+\", all_spam_ham_content)\n",
        "    words_frequency_in_all_folders = {}\n",
        "    for each_word in total_file_words:\n",
        "        each_word = each_word.lower()\n",
        "              # get dictionary of each word\n",
        "        if each_word in total_words_dictionary:\n",
        "            continue\n",
        "        else:    \n",
        "            if each_word not in stop_words:\n",
        "                total_words_dictionary[each_word] = 0\n",
        "                # get frequency of each word\n",
        "        if each_word in words_frequency_in_all_folders:\n",
        "            if each_word not in stop_words:\n",
        "                words_frequency_in_all_folders[each_word] = words_frequency_in_all_folders[each_word] + 1\n",
        "        else:\n",
        "            if each_word not in stop_words:\n",
        "                words_frequency_in_all_folders[each_word] = 1\n",
        "    # bag of words for spam emails\n",
        "    spam_email_bag_of_words = []\n",
        "    words_frenquency_spam_email_all_folders = {}\n",
        "    for each_spam_email in all_spam_emails_raw_content:\n",
        "        temporary_dictionary = copy.deepcopy(total_words_dictionary)\n",
        "        words_in_each_spam_email = re.findall(\"[a-zA-Z]+\", each_spam_email) # only words in alphabets\n",
        "        for each_word in words_in_each_spam_email:\n",
        "            each_word = each_word.lower()\n",
        "            if each_word in temporary_dictionary:\n",
        "                temporary_dictionary[each_word] = temporary_dictionary[each_word] + 1\n",
        "        # Here we store all the words in the spam dataset\n",
        "        words_frenquency_spam_email_all_folders = Counter(words_frenquency_spam_email_all_folders) + Counter(temporary_dictionary) # total frenquency for spam emails\n",
        "        spam_email_bag_of_words.append(temporary_dictionary) # give frenquency of words in each spam email\n",
        "    # bag of words for ham emails\n",
        "    words_frenquency_ham_email_in_all_folders = {}\n",
        "    ham_email_bag_of_words = []\n",
        "    for each_ham_mail in all_ham_emails_raw_content:\n",
        "        temporary_dictionary = copy.deepcopy(total_words_dictionary)\n",
        "        words_in_each_ham_email = re.findall(\"[a-zA-Z]+\", each_ham_mail)\n",
        "        for each_word in words_in_each_ham_email:\n",
        "            each_word = each_word.lower()\n",
        "            if each_word in temporary_dictionary:\n",
        "                temporary_dictionary[each_word] = temporary_dictionary[each_word] + 1\n",
        "        # Here we store all the words in the ham dataset\n",
        "        words_frenquency_ham_email_in_all_folders = Counter(words_frenquency_ham_email_in_all_folders) + Counter(temporary_dictionary) # total frequency for ham emails\n",
        "        ham_email_bag_of_words.append(temporary_dictionary) # give frenquency of words in each ham email\n",
        "    return spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bernoulli model"
      ],
      "metadata": {
        "id": "HmGJau1zgHmT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  path_of_dataset_name: The path of folder. For example, 'content/enron1'\n",
        "*  True_or_False_train_set: True means it is train set; otherwise, it is test set"
      ],
      "metadata": {
        "id": "hQeaw3UcXPLI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bernoulli_model(path_of_dataset_name, True_or_False_train_set):\n",
        "    all_spam_emails_raw_content, all_ham_emails_raw_content, all_spam_ham_content, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset = import_data_train_or_test(path_of_dataset_name, True_or_False_train_set)\n",
        "    total_words_dictionary = {}\n",
        "    total_file_words = re.findall(\"[a-zA-Z]+\", all_spam_ham_content)\n",
        "    # at first we find all the words in the given dataset and find the occurrences in the whole dataset\n",
        "    for each_word in total_file_words:   \n",
        "        each_word = each_word.lower() # lower case form\n",
        "        if each_word in total_words_dictionary:\n",
        "            continue\n",
        "        else:\n",
        "            if each_word not in stop_words:\n",
        "                total_words_dictionary[each_word] = 0\n",
        "    # bernoulli model for spam\n",
        "    spam_email_bernoulli_model = []\n",
        "    words_occurence_spam_email_all_folders = {} #\n",
        "    for each_spam_email in all_spam_emails_raw_content:\n",
        "        \n",
        "        temporary_dictionary = copy.deepcopy(total_words_dictionary)\n",
        "        words_in_each_spam_email = re.findall(\"[a-zA-Z]+\", each_spam_email)\n",
        "        for each_word in words_in_each_spam_email:\n",
        "            each_word = each_word.lower() # lower case form\n",
        "            if each_word in temporary_dictionary:\n",
        "                temporary_dictionary[each_word] = 1           \n",
        "                words_occurence_spam_email_all_folders[each_word] = 1 \n",
        "        spam_email_bernoulli_model.append(temporary_dictionary)\n",
        "    # bernoulli model for ham\n",
        "    ham_email_bernoulli_model = []\n",
        "    words_occurence_ham_email_in_all_folders = {}\n",
        "    for each_ham_mail in all_ham_emails_raw_content:\n",
        "        \n",
        "        temporary_dictionary = copy.deepcopy(total_words_dictionary)\n",
        "        words_in_each_ham_email = re.findall(\"[a-zA-Z]+\", each_ham_mail)\n",
        "        for each_word in words_in_each_ham_email:\n",
        "            each_word = each_word.lower()\n",
        "            if each_word in temporary_dictionary:\n",
        "                temporary_dictionary[each_word] = 1\n",
        "                words_occurence_ham_email_in_all_folders[each_word] = 1\n",
        "        ham_email_bernoulli_model.append(temporary_dictionary)\n",
        "    return spam_email_bernoulli_model, ham_email_bernoulli_model, words_occurence_spam_email_all_folders, words_occurence_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary"
      ],
      "metadata": {
        "id": "T6_J3BD8gLBJ"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Function"
      ],
      "metadata": {
        "id": "GeH6eykwD48E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(real_y, predicted_y):\n",
        "    correct_predictions = 0\n",
        "    for each in range(len(real_y)):\n",
        "        if real_y[each] == predicted_y[each]:\n",
        "            correct_predictions += 1\n",
        "    return correct_predictions / len(real_y)\n",
        "\n",
        "\n",
        "def precision(real_y, predicted_y):\n",
        "    true_positives = 0\n",
        "    false_positives = 0\n",
        "    for each in range(len(real_y)):\n",
        "        if real_y[each] == predicted_y[each] and predicted_y[each] == 1:\n",
        "            true_positives += 1\n",
        "        if real_y[each] != predicted_y[each] and predicted_y[each] == 1:\n",
        "            false_positives += 1\n",
        "    return true_positives / (true_positives + false_positives)\n",
        "\n",
        "\n",
        "def recall(real_y, predicted_y):\n",
        "    true_positives = 0\n",
        "    false_negetives = 0\n",
        "    for each in range(len(real_y)):\n",
        "        if real_y[each] == predicted_y[each] and predicted_y[each] == 1:\n",
        "            true_positives += 1\n",
        "        if real_y[each] != predicted_y[each] and predicted_y[each] == 0:\n",
        "            false_negetives += 1\n",
        "    return true_positives / (true_positives + false_negetives)\n",
        "\n",
        "\n",
        "def f1_score(recall, precision):\n",
        "    return (2 * recall * precision) / (recall + precision)"
      ],
      "metadata": {
        "id": "R7wQPb1fD2ti"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## multinomial Naive Bayes"
      ],
      "metadata": {
        "id": "fhcZ762yjlPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* total_words_dictionary: dictionary of all of words in dataset\n",
        "* spam_email_bag_of_words:  frequence of words in each spam email(from the first to the last email)\n",
        "* ham_email_bag_of_words: frequence of words in each ham email(from the first to the last email)\n",
        "* words_frequency_in_all_folders: total words frequencies\n",
        "* words_frenquency_spam_email_all_folders: total frequencies in all spam emails\n",
        "* words_frenquency_ham_email_in_all_folders: total frequencies in all ham emails\n",
        "* num_of_files_whole_dataset: the number of files of whole dataset\n",
        "* num_of_files_spam_dataset: the number of files of spam dataset\n",
        "* num_of_files_ham_dataset: the number of files of ham dataset"
      ],
      "metadata": {
        "id": "CoxK9n-aHe3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* log_prior: $log(P(Y=c_i))$\n",
        "* log_conditional_probability: $[log(p_{ij})]$, which is a vector\n"
      ],
      "metadata": {
        "id": "ootmOTMzzTRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_multinomial_naive_bayes(spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders,\n",
        "                         words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset,\n",
        "                         num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary):\n",
        "    # variables to store the values\n",
        "    log_prior = {}\n",
        "    log_conditional_probability = {}\n",
        "    log_conditional_probability[\"spam\"] = {}\n",
        "    log_conditional_probability[\"ham\"] = {}\n",
        "    log_conditional_probability_of_non_occurring_word = {}\n",
        "    log_conditional_probability_of_non_occurring_word[\"spam\"] = {}\n",
        "    log_conditional_probability_of_non_occurring_word[\"ham\"] = {}\n",
        "    \n",
        "    # log_priors for the spam and ham dataset\n",
        "    log_prior[\"spam\"] = log(num_of_files_spam_dataset / float(num_of_files_whole_dataset)) # log-scale to avoid underflow\n",
        "    total_number_of_words_in_ham = sum(words_frenquency_ham_email_in_all_folders.values())\n",
        "    log_prior[\"ham\"] = log(num_of_files_ham_dataset / float(num_of_files_whole_dataset))\n",
        "    total_number_of_words_in_spam = sum(words_frenquency_ham_email_in_all_folders.values())\n",
        "    # Now we calculate the values for the conditional probabilities\n",
        "    for each_word in list(words_frenquency_spam_email_all_folders):\n",
        "        log_conditional_probability[\"spam\"][each_word] = log((words_frenquency_spam_email_all_folders[each_word] + 1) / (\n",
        "            float(total_number_of_words_in_spam + len(words_frequency_in_all_folders))))\n",
        "\n",
        "    # same procedure for ham docs\n",
        "    for each_word in list(words_frenquency_ham_email_in_all_folders):\n",
        "        log_conditional_probability[\"ham\"][each_word] = log((words_frenquency_ham_email_in_all_folders[each_word] + 1) / (\n",
        "            float(total_number_of_words_in_ham + len(words_frequency_in_all_folders))))\n",
        "    # log conditional probabilities not in the training dataset\n",
        "    log_conditional_probability_of_non_occurring_word[\"ham\"] = log(\n",
        "        1 / (float(total_number_of_words_in_ham + len(words_frequency_in_all_folders))))\n",
        "    log_conditional_probability_of_non_occurring_word[\"spam\"] = log(\n",
        "        1 / (float(total_number_of_words_in_spam + len(words_frequency_in_all_folders))))\n",
        "    return log_prior, log_conditional_probability, log_conditional_probability_of_non_occurring_word"
      ],
      "metadata": {
        "id": "Nue1byXwh_pI"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* log_conditional_probability_of_non_occurring_word: log conditional probability for each word in the testing set which is not in the training data\n",
        "* an_email_bag_of_words_test: an email in test dataset we want to classify\n",
        "* 1: spam 0: ham"
      ],
      "metadata": {
        "id": "WBlFfg5ECaUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_multinomial_naive_bayes(log_prior, log_conditional_probability, log_conditional_probability_of_non_occurring_word,\n",
        "                                 an_email_bag_of_words_test):\n",
        "    weight_of_class = {}\n",
        "    for each_class in list(log_prior):\n",
        "        weight_of_class[each_class] = log_prior[each_class]\n",
        "        for each_word in list(an_email_bag_of_words_test):\n",
        "            if an_email_bag_of_words_test[each_word] != 0:\n",
        "                try:\n",
        "                    weight_of_class[each_class] += log_conditional_probability[each_class][each_word]\n",
        "                # This is the case if the word was not in the train data and thus the laplace pruning gives this result\n",
        "                except KeyError:\n",
        "                    weight_of_class[each_class] += log_conditional_probability_of_non_occurring_word[each_class]\n",
        "    # Here we are taking spam as 1 and ham as -1\n",
        "    if weight_of_class[\"spam\"] > weight_of_class[\"ham\"]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "lny0qN0DiVgw"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_multinomial_naive_bayes(path_of_dataset_name):\n",
        "    \"\"\"\n",
        "    This is the method used for evaluation of multinomial NB on a particular dataset\n",
        "    :param path_of_dataset_name: This is the given dataset name\n",
        "    :return: The method returns the accuracy, precision, recall and f1_score for the given dataset\n",
        "    \"\"\"\n",
        "    # We first import training data for the training\n",
        "    try:\n",
        "        spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bag_of_words_model(\n",
        "            path_of_dataset_name, True)\n",
        "    except:\n",
        "        print (\"wrong file\")\n",
        "        exit(-1)\n",
        "    log_prior, log_conditional_probability, log_conditional_probability_of_non_occurring_word = train_multinomial_naive_bayes(\n",
        "        spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders, words_frenquency_spam_email_all_folders,\n",
        "        words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset,\n",
        "        total_words_dictionary)\n",
        "    # We now import the data for testing\n",
        "    spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bag_of_words_model(\n",
        "        path_of_dataset_name, False)\n",
        "    # We calculate the evaluation metric\n",
        "    # Here we first predict for the spam class and then the ham class\n",
        "    spam_predict = []\n",
        "    for each_document in spam_email_bag_of_words:\n",
        "        spam_predict.append(test_multinomial_naive_bayes(log_prior, log_conditional_probability,\n",
        "                                                                                  log_conditional_probability_of_non_occurring_word,\n",
        "                                                                                  each_document))\n",
        "    # We  are taking spam as 1\n",
        "    spam_actual = [1] * len(spam_predict)\n",
        "    ham_predict = []\n",
        "    for each_document in ham_email_bag_of_words:\n",
        "        ham_predict.append(test_multinomial_naive_bayes(log_prior, log_conditional_probability,\n",
        "                                                                                 log_conditional_probability_of_non_occurring_word,\n",
        "                                                                                 each_document))\n",
        "    ham_actual = [0] * len(ham_predict)\n",
        "    total_actual = spam_actual + ham_actual\n",
        "    total_predict = spam_predict + ham_predict\n",
        "    # Now we find the evaluation metrics for the method\n",
        "    accur = accuracy(total_actual, total_predict)\n",
        "    prec = precision(total_actual, total_predict)\n",
        "    rec = recall(total_actual, total_predict)\n",
        "    f1 = f1_score(rec, prec)\n",
        "    return accur, prec, rec, f1"
      ],
      "metadata": {
        "id": "wp8MEvLr4Ufw"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "accuracy, precision, recall, and F1 score"
      ],
      "metadata": {
        "id": "GDCReHPFGFmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_multinomial_naive_bayes('/content/enron1')"
      ],
      "metadata": {
        "id": "BkOThAE26GEy",
        "outputId": "155bd2c5-f86b-46de-c257-1f57b31edfee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8114035087719298, 1.0, 0.4228187919463087, 0.5943396226415094)"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_multinomial_naive_bayes('/content/enron4')"
      ],
      "metadata": {
        "id": "2pfFHiHzM-s0",
        "outputId": "cd66ee8e-b08c-40df-fb77-d1b7e1b4798e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8913443830570903, 0.8688888888888889, 1.0, 0.929845422116528)"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_multinomial_naive_bayes('/content/hw1')"
      ],
      "metadata": {
        "id": "n8pJkOCVNDzN",
        "outputId": "37350dc2-da4d-4ccb-f40f-ef1069f2ef96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8326359832635983, 1.0, 0.38461538461538464, 0.5555555555555556)"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## discrete Naive Bayes"
      ],
      "metadata": {
        "id": "LkvPhjn-9tOW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* total_words_dictionary: total words dictionary\n",
        "* words_occurence_spam_email_all_folders: bernoulli model of all the spam folders\n",
        "* words_occurence_ham_email_in_all_folders: bernoulli model of all the spam folders"
      ],
      "metadata": {
        "id": "QxfimRifhBOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discrete_naive_bayes(spam_email_bernoulli_model, ham_email_bernoulli_model,\n",
        "                               words_occurence_spam_email_all_folders, words_occurence_ham_email_in_all_folders, num_of_files_whole_dataset,\n",
        "                               num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary):\n",
        "    log_prior = {}\n",
        "    # variables to store the values\n",
        "    log_conditional_probability = {}\n",
        "    log_conditional_probability[\"spam\"] = {}\n",
        "    log_conditional_probability[\"ham\"] = {}\n",
        "    log_conditional_probability_of_non_occurring_word = {}\n",
        "    log_conditional_probability_of_non_occurring_word[\"spam\"] = {}\n",
        "    log_conditional_probability_of_non_occurring_word[\"ham\"] = {}\n",
        "    # log_prior of both the classes\n",
        "    log_prior[\"spam\"] = log(num_of_files_spam_dataset / num_of_files_whole_dataset)\n",
        "    log_prior[\"ham\"] = log(num_of_files_ham_dataset / num_of_files_whole_dataset)\n",
        "    # We are doing 1-laplace smoothing and thus we add 1 in the numerator and 2 in denominator(since each word can\n",
        "    # have two values 0, 1 )\n",
        "    sum_of_words_occurence_each_spam_email_all_folders = {}\n",
        "    for ind in range(len(spam_email_bernoulli_model)):\n",
        "      sum_of_words_occurence_each_spam_email_all_folders = Counter(sum_of_words_occurence_each_spam_email_all_folders)+Counter(spam_email_bernoulli_model[ind])\n",
        "\n",
        "    sum_of_words_occurence_each_ham_email_all_folders = {}\n",
        "    for ind in range(len(ham_email_bernoulli_model)):\n",
        "      sum_of_words_occurence_each_ham_email_all_folders = Counter(sum_of_words_occurence_each_ham_email_all_folders)+Counter(ham_email_bernoulli_model[ind])\n",
        "\n",
        "    for each_word in words_occurence_spam_email_all_folders:     \n",
        "        log_conditional_probability[\"spam\"][each_word] = log(\n",
        "            1 + sum_of_words_occurence_each_spam_email_all_folders[each_word] / (num_of_files_spam_dataset + 2)) # num_of_files_spam_dataset represents the number of spam emails\n",
        "\n",
        "    for each_word in words_occurence_ham_email_in_all_folders:\n",
        "        log_conditional_probability[\"ham\"][each_word] = log(\n",
        "            1 + sum_of_words_occurence_each_ham_email_all_folders[each_word] / num_of_files_ham_dataset + 2)\n",
        "    # log probabilities for the word not in the training data and appear in the testing data\n",
        "    log_conditional_probability_of_non_occurring_word[\"ham\"] = log(1 / (num_of_files_ham_dataset + 2))\n",
        "    log_conditional_probability_of_non_occurring_word[\"spam\"] = log(1 / (num_of_files_spam_dataset + 2))\n",
        "    return log_prior, log_conditional_probability, log_conditional_probability_of_non_occurring_word"
      ],
      "metadata": {
        "id": "0rDIZlyc4bSI"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1: spam 0: ham"
      ],
      "metadata": {
        "id": "gkCZyZlWD-Xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_discrete_naive_bayes(log_prior, log_conditional_probability, log_conditional_probability_of_non_occurring_word,\n",
        "                              an_email_bag_of_words_test):\n",
        "    weight_of_class = {}\n",
        "    # find the words in the given documents for each class and find the numerator of posterior\n",
        "    for each_class in list(log_prior):\n",
        "        weight_of_class[each_class] = log_prior[each_class]\n",
        "        for each_word in list(an_email_bag_of_words_test):\n",
        "            if an_email_bag_of_words_test[each_word] != 0:\n",
        "                try:\n",
        "                    weight_of_class[each_class] += log_conditional_probability[each_class][each_word]\n",
        "                # This is the case if the word was not in the train data and thus the laplace pruning gives this result\n",
        "                except KeyError:\n",
        "                    weight_of_class[each_class] += log_conditional_probability_of_non_occurring_word[each_class]\n",
        "    if weight_of_class[\"spam\"] > weight_of_class[\"ham\"]:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "metadata": {
        "id": "COM5-RvSBWJI"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_discrete_naive_bayes(path_of_dataset_name):\n",
        "    # import training data for training\n",
        "    try:\n",
        "        spam_email_bernoulli_model, ham_email_bernoulli_model, words_occurence_spam_email_all_folders, words_occurence_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bernoulli_model(\n",
        "            path_of_dataset_name, True)\n",
        "    except:\n",
        "        print (\"wrong file\")\n",
        "        exit(-1)\n",
        "    log_prior, log_conditional_probability, log_conditional_probability_of_non_occurring_word = train_discrete_naive_bayes(\n",
        "        spam_email_bernoulli_model, ham_email_bernoulli_model, words_occurence_spam_email_all_folders, words_occurence_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset,\n",
        "        total_words_dictionary)\n",
        "    # import the data for testing\n",
        "    spam_email_bernoulli_model, ham_email_bernoulli_model, words_occurence_spam_email_all_folders, words_occurence_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bernoulli_model(\n",
        "        path_of_dataset_name, False)\n",
        "    # We calculate the evaluation metric\n",
        "    # Here we first predict for the spam class and then the ham class\n",
        "    spam_predict = []\n",
        "    for each_document in spam_email_bernoulli_model:\n",
        "        spam_predict.append(test_discrete_naive_bayes(log_prior, log_conditional_probability,\n",
        "                                                                           log_conditional_probability_of_non_occurring_word,\n",
        "                                                                           each_document))\n",
        "    # We  are taking spam as 1\n",
        "    spam_actual = [1] * len(spam_predict)\n",
        "    ham_predict = []\n",
        "    for each_document in ham_email_bernoulli_model:\n",
        "        ham_predict.append(test_discrete_naive_bayes(log_prior, log_conditional_probability,\n",
        "                                                                          log_conditional_probability_of_non_occurring_word,\n",
        "                                                                          each_document))\n",
        "    ham_actual = [0] * len(ham_predict)\n",
        "    total_actual = spam_actual + ham_actual\n",
        "    total_predict = spam_predict + ham_predict\n",
        "    # evaluation\n",
        "    accur = accuracy(total_actual, total_predict)\n",
        "    prec = precision(total_actual, total_predict)\n",
        "    rec = recall(total_actual, total_predict)\n",
        "    f1 = f1_score(rec, prec)\n",
        "    return accur, prec, rec, f1"
      ],
      "metadata": {
        "id": "vcPSqNxrCL7U"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_discrete_naive_bayes('/content/enron1')"
      ],
      "metadata": {
        "id": "poz3c7x4Cwe9",
        "outputId": "81f38339-771c-42d9-df55-7d0ab548ffec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8947368421052632,\n",
              " 0.9902912621359223,\n",
              " 0.6845637583892618,\n",
              " 0.8095238095238094)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_discrete_naive_bayes('/content/enron4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ml7Wjw5Q04Z",
        "outputId": "dd2f678a-f438-406a-8853-cbcff0876a46"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9060773480662984, 0.967032967032967, 0.9002557544757033, 0.9324503311258278)"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_discrete_naive_bayes('/content/hw1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjHrKdWFQ0lM",
        "outputId": "9d85b97a-fbf6-47cc-d372-1e5fdad4af43"
      },
      "execution_count": 194,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9163179916317992, 1.0, 0.6923076923076923, 0.8181818181818181)"
            ]
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MCAP Logistic Regression"
      ],
      "metadata": {
        "id": "ohb9c4l_K-cg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   spam_email_model: spam_email_bag_of_words or spam_email_bernoulli_model\n",
        "*   ham_email_model: ham_mail_bag_of_words or ham_email_bernoulli_model\n",
        "\n"
      ],
      "metadata": {
        "id": "SglBbNMhTEvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_into_validation_and_train(spam_email_model, ham_email_model):\n",
        "    # Here spam is 1 and ham is 0 (since we are using sigmoid)\n",
        "    for ind in range(len(spam_email_model)):\n",
        "        spam_email_model[ind][\"the_class_of_the_document\"] = 1\n",
        "        spam_email_model[ind][\"zero_weight\"] = 1\n",
        "    for ind in range(len(ham_email_model)):\n",
        "        ham_email_model[ind][\"the_class_of_the_document\"] = 0\n",
        "        ham_email_model[ind][\"zero_weight\"] = 1\n",
        "    all_data = spam_email_model + ham_email_model\n",
        "    # We are using this step to shuffle our data so that different data goes into training and testing everything\n",
        "    random.shuffle(all_data)\n",
        "    # 70 percent of the data for traning and 30 percent of the data for validation\n",
        "    train_data = all_data[0: int(len(all_data) * .70)]\n",
        "    validation_data = all_data[int(len(all_data) * .70): -1]\n",
        "    return train_data, validation_data"
      ],
      "metadata": {
        "id": "TKRwBY9WoyOj"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "value: $w_0+\\sum_{i=1}^nw_iX_i$"
      ],
      "metadata": {
        "id": "3zHZxoqe3GwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output_for_class(weights, inputs):\n",
        "    value = weights['zero_weight'] * 1\n",
        "    for each in inputs:\n",
        "        if each == 'the_class_of_the_document' or each == 'zero_weight':\n",
        "            continue\n",
        "        else:\n",
        "            if each in weights and each in inputs:\n",
        "                value = value + (weights[each] * inputs[each])\n",
        "    return value"
      ],
      "metadata": {
        "id": "xfYMOQqdKQ_f"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$P(Y=1|X)=\\frac{1}{1+exp(-(w_0+\\sum_{i=1}^nw_iX_i))}$"
      ],
      "metadata": {
        "id": "Ep5wrQLD2UL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_posterior(weights, inputs):\n",
        "    value = weights['zero_weight'] * 1\n",
        "    for each in inputs:\n",
        "        if each == 'the_class_of_the_document' or each == 'zero_weight':\n",
        "            continue\n",
        "        else:\n",
        "            if each in weights and each in inputs:\n",
        "                value = value + (weights[each] * inputs[each])\n",
        "    return 1 / (1 + np.exp(-value))"
      ],
      "metadata": {
        "id": "d1A9mB5WKUMO"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This function return the optimized weights\n",
        "*   $W_0 ← w_0+\\eta \\sum_l (Y^l-\\hat{P}(Y^l=1\\mid X^l,W))-\\eta \\lambda w_0$\n",
        "*   $W_i ← w_i+\\eta \\sum_l X_i^l(Y^l-\\hat{P}(Y^l=1\\mid X^l,W))-\\eta \\lambda w_i$\n",
        "*   eta: $\\eta$ - learning rate\n",
        "*   lambda_parameter: $\\lambda$\n",
        "\n"
      ],
      "metadata": {
        "id": "YWq3Gc410QQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mcap_logistic_regression(train_data, total_words_dictionary, eta, lambda_parameter, number_of_iterations):\n",
        "    # w_0 outside the array\n",
        "    weights = copy.deepcopy(total_words_dictionary)\n",
        "    for each in weights:\n",
        "        weights[each] = 0\n",
        "    weights['zero_weight'] = 0\n",
        "    # update all the weights\n",
        "    for each in range(number_of_iterations):\n",
        "        for each_instance in train_data:\n",
        "            posterior = get_posterior(weights, each_instance)\n",
        "            sum_of_vals = 0\n",
        "            for each_weight in weights:\n",
        "                # if the weight is not equal to 0 or not\n",
        "                if each_instance[each_weight] != 0:\n",
        "                    if each_weight == \"zero_weight\":\n",
        "                        sum_of_vals = sum_of_vals + eta * (\n",
        "                                each_instance[\"the_class_of_the_document\"] - posterior)\n",
        "                    else:\n",
        "                        sum_of_vals = sum_of_vals + eta * (each_instance[each_weight] * (\n",
        "                                each_instance[\"the_class_of_the_document\"] - posterior))\n",
        "                    weights[each_weight] = weights[each_weight] + sum_of_vals - eta * lambda_parameter * weights[\n",
        "                        each_weight]\n",
        "    return weights"
      ],
      "metadata": {
        "id": "0cJCTjs4KXWJ"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_mcap_logistic_regression(test_example, weights):\n",
        "    value = get_output_for_class(weights, test_example)\n",
        "    # 0 is ham and 1 is spam\n",
        "    if value < 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "metadata": {
        "id": "wByy4H-bKai1"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do grid search to find $\\lambda$ from $1$ to $8$ increasing $2$ at a time."
      ],
      "metadata": {
        "id": "rHy0Xbfx4Kkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mcap_validation(train_data, validation_data, total_words_dictionary):\n",
        "    \n",
        "    eta = 0.01\n",
        "    max_accuracy = 0\n",
        "    best_lambda_value = 2\n",
        "    # We take the range from 1 increasing 2 at a time\n",
        "    for each_lambda_value in range(1, 8, 2):\n",
        "        # training model using training dataset\n",
        "        weights = train_mcap_logistic_regression(train_data, total_words_dictionary, eta, each_lambda_value, 50)\n",
        "        correct_classification = 0\n",
        "        # We test on the validation data\n",
        "        for each_document in validation_data:\n",
        "            output = test_mcap_logistic_regression(each_document, weights)\n",
        "            if output == each_document[\"the_class_of_the_document\"]:\n",
        "                correct_classification += 1\n",
        "        accuracy = correct_classification / len(validation_data)\n",
        "        # get the best lambda value\n",
        "        if accuracy > max_accuracy:\n",
        "            max_accuracy = accuracy\n",
        "            best_lambda_value = each_lambda_value\n",
        "    return best_lambda_value"
      ],
      "metadata": {
        "id": "G5fjQ0U8Kg2O"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_MCAP_bag_of_words(path_of_dataset_name):\n",
        "    # import training data for the training\n",
        "    try:\n",
        "        spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bag_of_words_model(\n",
        "            path_of_dataset_name, True)\n",
        "    except:\n",
        "        print (\"wrong file\")\n",
        "        exit(-1)\n",
        "    # divide training data into training and validation data\n",
        "    train_data, validation_data = divide_into_validation_and_train(spam_email_bag_of_words,\n",
        "                                                                                            ham_email_bag_of_words)\n",
        "    # get the lambda by using the grid search algorithm\n",
        "    lambda_parameter = mcap_validation(train_data, validation_data, total_words_dictionary)\n",
        "    # merge the training data and the validation data\n",
        "    train_data = train_data + validation_data\n",
        "    eta = 0.01\n",
        "    # In this step the algorithm learns the weights\n",
        "    weights = train_mcap_logistic_regression(train_data, total_words_dictionary, eta,\n",
        "                                                                      lambda_parameter, 100)\n",
        "    # import testing data\n",
        "    spam_email_bag_of_words_test, ham_email_bag_of_words_test, words_frequency_in_all_folders_test, words_frenquency_spam_email_all_folders_test, words_frenquency_ham_email_in_all_folders_test, num_of_files_whole_dataset_test, num_of_files_spam_dataset_test, num_of_files_ham_dataset_test, total_words_dictionary_test = bag_of_words_model(\n",
        "        path_of_dataset_name, False)\n",
        "    spam_predict = []\n",
        "    # do prediction given test dataset\n",
        "    for each_document in spam_email_bag_of_words_test:\n",
        "        spam_predict.append(test_mcap_logistic_regression(each_document, weights))\n",
        "    # spam: 1 ham: 0\n",
        "    spam_actual = [1] * len(spam_predict)\n",
        "    ham_predict = []\n",
        "    for each_document in ham_email_bag_of_words_test:\n",
        "        ham_predict.append(test_mcap_logistic_regression(each_document, weights))\n",
        "    ham_actual = [0] * len(ham_predict)\n",
        "    total_actual = spam_actual + ham_actual\n",
        "    total_predict = spam_predict + ham_predict\n",
        "    # Now we find the evaluation metrics for the method\n",
        "    accur = accuracy(total_actual, total_predict)\n",
        "    prec = precision(total_actual, total_predict)\n",
        "    rec = recall(total_actual, total_predict)\n",
        "    f1 = f1_score(rec, prec)\n",
        "    return accur, prec, rec, f1, lambda_parameter\n",
        "    "
      ],
      "metadata": {
        "id": "aa8lu720Tjvf"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_MCAP_bag_of_words('/content/enron1')"
      ],
      "metadata": {
        "id": "7ZiOmvAnUI61",
        "outputId": "006b635b-3921-4343-db93-fdd2e297d868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 202,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9122807017543859,\n",
              " 0.9658119658119658,\n",
              " 0.7583892617449665,\n",
              " 0.849624060150376,\n",
              " 3)"
            ]
          },
          "execution_count": 202,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_MCAP_bag_of_words('/content/enron4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKZA6sunEVqf",
        "outputId": "ef228f03-a838-4b65-dffb-eba6e3f09b75"
      },
      "execution_count": 203,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9613259668508287, 0.9490291262135923, 1.0, 0.9738480697384807, 1)"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_MCAP_bag_of_words('/content/hw1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2zKh0r0EYwe",
        "outputId": "febc5429-f02a-4bfd-a6c3-11eafb544b45"
      },
      "execution_count": 204,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9246861924686193,\n",
              " 0.9519230769230769,\n",
              " 0.7615384615384615,\n",
              " 0.8461538461538461,\n",
              " 5)"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_MCAP_bernoulli_model(path_of_dataset_name):\n",
        "    # import training data for the training\n",
        "    try:\n",
        "        spam_email_bernoulli_model1, ham_email_bernoulli_model1, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bernoulli_model(\n",
        "            path_of_dataset_name, True)\n",
        "    except:\n",
        "        print (\"wrong file\")\n",
        "        exit(-1)\n",
        "    # divide training data into training and validation data\n",
        "    train_data, validation_data = divide_into_validation_and_train(spam_email_bernoulli_model1,\n",
        "                                                                                            ham_email_bernoulli_model1)\n",
        "    # get the lambda value by using the grid search algorithm\n",
        "    lambda_parameter = mcap_validation(train_data, validation_data, total_words_dictionary)\n",
        "    eta = 0.01\n",
        "    # merge the training data and the validation data again\n",
        "    train_data = train_data + validation_data\n",
        "    # In this step the algorithm learns the weights\n",
        "    weights = train_mcap_logistic_regression(train_data, total_words_dictionary, eta,\n",
        "                                                                      lambda_parameter, 100)\n",
        "    # import testing data\n",
        "    spam_email_bernoulli_model_test, ham_email_bernoulli_model_test, words_frenquency_spam_email_all_folders_test, words_frenquency_ham_email_in_all_folders_test, num_of_files_whole_dataset_test, num_of_files_spam_dataset_test, num_of_files_ham_dataset_test, total_words_dictionary_test = bernoulli_model(\n",
        "        path_of_dataset_name, False)\n",
        "    spam_predict = []\n",
        "    # do prediction given test dataset\n",
        "    for each_document in spam_email_bernoulli_model_test:\n",
        "        spam_predict.append(test_mcap_logistic_regression(each_document, weights))\n",
        "    # spam: 1 ham: 0\n",
        "    spam_actual = [1] * len(spam_predict)\n",
        "    ham_predict = []\n",
        "    for each_document in ham_email_bernoulli_model_test:\n",
        "        ham_predict.append(test_mcap_logistic_regression(each_document, weights))\n",
        "    ham_actual = [0] * len(ham_predict)\n",
        "    total_actual = spam_actual + ham_actual\n",
        "    total_predict = spam_predict + ham_predict\n",
        "    # Now we find the evaluation metrics for the method\n",
        "    accur = accuracy(total_actual, total_predict)\n",
        "    prec = precision(total_actual, total_predict)\n",
        "    rec = recall(total_actual, total_predict)\n",
        "    f1 = f1_score(rec, prec)\n",
        "    return accur, prec, rec, f1, lambda_parameter"
      ],
      "metadata": {
        "id": "SBuzx9HjTeiO"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_MCAP_bernoulli_model('/content/enron1')"
      ],
      "metadata": {
        "id": "XyloFmc9YgQI",
        "outputId": "07a0ab7f-bb17-4b8d-acaf-f025e48766e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 206,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.8947368421052632,\n",
              " 0.9809523809523809,\n",
              " 0.6912751677852349,\n",
              " 0.8110236220472441,\n",
              " 7)"
            ]
          },
          "execution_count": 206,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_MCAP_bernoulli_model('/content/enron4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kngelhJEdgV",
        "outputId": "210dcae8-ead1-43bc-c146-d5da8b8fb51a"
      },
      "execution_count": 207,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.9613259668508287, 0.9490291262135923, 1.0, 0.9738480697384807, 1)"
            ]
          },
          "execution_count": 207,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_MCAP_bernoulli_model('/content/hw1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnGEvr5oEfzN",
        "outputId": "acab1da1-9672-428e-f112-2e507b211f5b"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9288702928870293,\n",
              " 0.9705882352941176,\n",
              " 0.7615384615384615,\n",
              " 0.8534482758620688,\n",
              " 5)"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SGDClassifier"
      ],
      "metadata": {
        "id": "XcfQTJ6xbM-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parameter_tuning(validation_x, validation_y):\n",
        "    parameters_to_be_tuned = {'alpha': (0.01, 0.05),\n",
        "                              'max_iter': (range(500, 3000, 1000)),\n",
        "                              'learning_rate': ('optimal', 'invscaling', 'adaptive'),\n",
        "                              'eta0': (0.3, 0.7),\n",
        "                              'tol': (0.001, 0.005)\n",
        "                              }\n",
        "    SGDclassifier = SGDClassifier()\n",
        "    gridSearch = GridSearchCV(SGDclassifier, parameters_to_be_tuned, cv=5)\n",
        "    gridSearch.fit(validation_x, validation_y)\n",
        "    return gridSearch"
      ],
      "metadata": {
        "id": "2V6j8pavZf1z"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_SGD(train_x, train_y, classifier):\n",
        "    return classifier.fit(train_x, train_y)"
      ],
      "metadata": {
        "id": "Lh1xUbQda3qJ"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_SGD(trained_classifier, test_x, test_y):\n",
        "    predicted_y = []\n",
        "    for each_document in test_x:\n",
        "        predicted_y.append(trained_classifier.predict(np.reshape(each_document, (1, -1))))\n",
        "    return predicted_y, test_y"
      ],
      "metadata": {
        "id": "oG0n0eGAbCY3"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_data_for_SGD_classifier(data, words_list):\n",
        "    train_x = []\n",
        "    train_y = []\n",
        "    for each_document in data:\n",
        "        train_x_for_this_document = []\n",
        "        train_y.append(each_document[\"the_class_of_the_document\"])\n",
        "        for each_word in words_list:\n",
        "            # use a try except here since it may happen that the given word is not in the document\n",
        "            try:\n",
        "                train_x_for_this_document.append(each_document[each_word])\n",
        "            except:\n",
        "                # If the word is not in the test set then we just 0 as the input for the given word.\n",
        "                train_x_for_this_document.append(0)\n",
        "        train_x.append(train_x_for_this_document)\n",
        "    return train_x, train_y"
      ],
      "metadata": {
        "id": "sZCD9NpNbFIP"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_from_given_model(spam_email_model, ham_email_model):\n",
        "    for ind in range(len(spam_email_model)):\n",
        "        spam_email_model[ind][\"the_class_of_the_document\"] = 1\n",
        "    for ind in range(len(ham_email_model)):\n",
        "        ham_email_model[ind][\"the_class_of_the_document\"] = 0\n",
        "      # combine spam email_model with ham_email_model\n",
        "    all_data = spam_email_model + ham_email_model\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "rtuoRjlGbIA_"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def divide_into_validation_and_train(spam_email_model, ham_email_model):\n",
        "    # Here spam is 1 and ham is 0 (since we are using sigmoid)\n",
        "    for ind in range(len(spam_email_model)):\n",
        "        spam_email_model[ind][\"the_class_of_the_document\"] = 1\n",
        "    for ind in range(len(ham_email_model)):\n",
        "        ham_email_model[ind][\"the_class_of_the_document\"] = 0\n",
        "    all_data = spam_email_model + ham_email_model\n",
        "    # We are using this step to shuffle our data so that different data goes into training and testing everything\n",
        "    random.shuffle(all_data)\n",
        "    train_data = all_data[0: int(len(all_data) * .70)]\n",
        "    validation_data = all_data[int(len(all_data) * .70): -1]\n",
        "    return train_data, validation_data"
      ],
      "metadata": {
        "id": "k8ws0ur-oWNe"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_SGD_bag_of_words(path_of_dataset_name):\n",
        "    # We first import training data for the training\n",
        "    try:\n",
        "        spam_email_bag_of_words, ham_email_bag_of_words, words_frequency_in_all_folders, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bag_of_words_model(\n",
        "            path_of_dataset_name, True)\n",
        "        spam_email_bag_of_words_test, ham_email_bag_of_words_test, words_frequency_in_all_folders_test, words_frenquency_spam_email_all_folders_test, words_frenquency_ham_email_in_all_folders_test, num_of_files_whole_dataset_test, num_of_files_spam_dataset_test, num_of_files_ham_dataset_test, total_words_dictionary_test = bag_of_words_model(\n",
        "            path_of_dataset_name, False)\n",
        "    except:\n",
        "        print( \"wrong file\")\n",
        "        exit(-1)\n",
        "    train_data, validation_data = divide_into_validation_and_train(spam_email_bag_of_words, ham_email_bag_of_words)\n",
        "    test_data = get_data_from_given_model(spam_email_bag_of_words_test, ham_email_bag_of_words_test)\n",
        "    words_list = list(train_data[0])\n",
        "    # import the train, test and validation datasets\n",
        "    train_x, train_y = convert_data_for_SGD_classifier(train_data, words_list)\n",
        "    test_x, test_y = convert_data_for_SGD_classifier(test_data, words_list)\n",
        "    valid_x, valid_y = convert_data_for_SGD_classifier(validation_data, words_list)\n",
        "    # get the best parameters for the sklearn SGD classifier\n",
        "    classifier_model = parameter_tuning(valid_x, valid_y)\n",
        "    # In this step the classifier model is being trained on the training dataset\n",
        "    trained_classifier_model = train_SGD(train_x, train_y, classifier_model)\n",
        "    # In this step we find the output for the classifier.\n",
        "    predicted_y, actual_y = test_SGD(trained_classifier_model, test_x, test_y)\n",
        "    # Now calculate the evaluation metrics\n",
        "    \n",
        "    accur = accuracy(actual_y, predicted_y)\n",
        "    prec = precision(actual_y, predicted_y)\n",
        "    rec = recall(actual_y, predicted_y)\n",
        "    f1 = f1_score(rec, prec)\n",
        "    return accur, prec, rec, f1"
      ],
      "metadata": {
        "id": "C35VhuVwbk4r"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_SGD_bernoulli_model(path_of_dataset_name):\n",
        "    # We first import training data for the training\n",
        "    try:\n",
        "        spam_email_bernoulli_model1, ham_email_bernoulli_model1, words_frenquency_spam_email_all_folders, words_frenquency_ham_email_in_all_folders, num_of_files_whole_dataset, num_of_files_spam_dataset, num_of_files_ham_dataset, total_words_dictionary = bernoulli_model(\n",
        "            path_of_dataset_name, True)\n",
        "        spam_email_bernoulli_model_test, ham_email_bernoulli_model_test, words_frenquency_spam_email_all_folders_test, words_frenquency_ham_email_in_all_folders_test, num_of_files_whole_dataset_test, num_of_files_spam_dataset_test, num_of_files_ham_dataset_test, total_words_dictionary_test = bernoulli_model(\n",
        "            path_of_dataset_name, False)\n",
        "    except:\n",
        "        print (\"wrong file\")\n",
        "        exit(-1)\n",
        "    train_data, validation_data = divide_into_validation_and_train(spam_email_bernoulli_model1,\n",
        "                                                                                 ham_email_bernoulli_model1)\n",
        "    test_data = get_data_from_given_model(spam_email_bernoulli_model_test, ham_email_bernoulli_model_test)\n",
        "    words_list = list(train_data[0])\n",
        "    # import the train, test and validation datasets\n",
        "    train_x, train_y = convert_data_for_SGD_classifier(train_data, words_list)\n",
        "    test_x, test_y = convert_data_for_SGD_classifier(test_data, words_list)\n",
        "    valid_x, valid_y = convert_data_for_SGD_classifier(validation_data, words_list)\n",
        "    # get the best parameters for the sklearn SGD classifier\n",
        "    classifier_model = parameter_tuning(valid_x, valid_y)\n",
        "    # In this step the classifier model is being trained on the training dataset\n",
        "    trained_classifier_model = train_SGD(train_x, train_y, classifier_model)\n",
        "    # In this step we find the output for the classifier.\n",
        "    predicted_y, actual_y = test_SGD(trained_classifier_model, test_x, test_y)\n",
        "    # Now calculate the evaluation metrics\n",
        "    accur = accuracy(actual_y, predicted_y)\n",
        "    prec = precision(actual_y, predicted_y)\n",
        "    rec = recall(actual_y, predicted_y)\n",
        "    f1 = f1_score(rec, prec)\n",
        "    return accur, prec, rec, f1"
      ],
      "metadata": {
        "id": "SxYjDtPZbOsR"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_SGD_bag_of_words('/content/enron1')\n"
      ],
      "metadata": {
        "id": "dJPOlCXwcDyj",
        "outputId": "4d2fe755-6ea8-4429-8929-cdbc7d5c6fad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9780701754385965, 0.9371069182389937, 1.0, 0.9675324675324676)"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_SGD_bag_of_words('/content/enron4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jksD2H6ZoOB",
        "outputId": "092c4cb2-cd09-4870-d694-1246e6d7562c"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9834254143646409,\n",
              " 0.9798994974874372,\n",
              " 0.9974424552429667,\n",
              " 0.9885931558935361)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_SGD_bag_of_words('/content/hw1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0XaZ1U3ZpJO",
        "outputId": "dc8a4287-646c-4101-b93a-b51b230695be"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9811715481171548,\n",
              " 0.9481481481481482,\n",
              " 0.9846153846153847,\n",
              " 0.9660377358490566)"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_SGD_bernoulli_model('/content/enron1')"
      ],
      "metadata": {
        "id": "wZp09WdpcHtT",
        "outputId": "b0499cbf-c274-490a-9c2c-fa5c673cd817",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_SGD_bernoulli_model('/content/enron4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKhmPS9bZwyC",
        "outputId": "fe5493a7-03fa-4f63-d49a-bf93112debba"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.996316758747698, 0.9949109414758269, 1.0, 0.9974489795918366)"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_SGD_bernoulli_model('/content/hw1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvrKjGStZyhq",
        "outputId": "1f1be190-d42b-478e-e2d4-73ffe34322b8"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    }
  ]
}