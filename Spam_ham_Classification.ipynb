{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV8KhafU2b6f1whpA7AdzS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xuxiufeng/Spam_ham_Classification/blob/main/Spam_ham_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unzip files"
      ],
      "metadata": {
        "id": "NSGsuhQVRfMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!unzip enron1_test.zip\n",
        "!unzip enron1_train.zip\n",
        "!unzip enron4_test.zip\n",
        "!unzip enron4_train.zip\n",
        "!unzip hw1_test.zip\n",
        "!unzip hw1_train.zip"
      ],
      "metadata": {
        "id": "hOo__4fMYABH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "VFaNWGMs_hGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import collections\n",
        "import os \n",
        "import re\n",
        "import codecs\n",
        "import numpy\n",
        "import math"
      ],
      "metadata": {
        "id": "jfB3pmvem_w6"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = [\"a\",\"about\",\"above\",\"after\",\"again\",\"against\",\"all\",\"am\",\"an\",\"and\",\n",
        "\"any\",\"are\",\"aren't\",\"as\",\"at\",\"be\",\"because\",\"been\",\"before\",\"being\",\"below\",\n",
        "\"between\",\"both\",\"but\",\"by\",\"can't\",\"cannot\",\"could\",\"couldn't\",\"did\",\"didn't\",\n",
        "\"do\",\"does\",\"doesn't\",\"doing\",\"don't\",\"down\",\"during\",\"each\",\"few\",\"for\",\"from\",\n",
        "\"further\",\"had\",\"hadn't\",\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\"he\",\"he'd\",\n",
        "\"he'll\",\"he's\",\"her\",\"here\",\"here's\",\"hers\",\"herself\",\"him\",\"himself\",\"his\",\"how\",\n",
        "\"how's\",\"i\",\"i'd\",\"i'll\",\"i'm\",\"i've\",\"if\",\"in\",\"into\",\"is\",\"isn't\",\"it\",\"it's\",\"its\",\n",
        "\"itself\",\"let's\",\"me\",\"more\",\"most\",\"mustn't\",\"my\",\"myself\",\"no\",\"nor\",\"not\",\"of\",\n",
        "\"off\",\"on\",\"once\",\"only\",\"or\",\"other\",\"ought\",\"our\",\"ours\",\"ourselves\",\"out\",\"over\",\n",
        "\"own\",\"same\",\"shan't\",\"she\",\"she'd\",\"she'll\",\"she's\",\"should\",\"shouldn't\",\"so\",\"some\",\n",
        "\"such\",\"than\",\"that\",\"that's\",\"the\",\"their\",\"theirs\",\"them\",\"themselves\",\"then\",\"there\",\n",
        "\"there's\",\"these\",\"they\",\"they'd\",\"they'll\",\"they're\",\"they've\",\"this\",\"those\",\"through\",\n",
        "\"to\",\"too\",\"under\",\"until\",\"up\",\"very\",\"was\",\"wasn't\",\"we\",\"we'd\",\"we'll\",\"we're\",\"we've\",\n",
        "\"were\",\"weren't\",\"what\",\"what's\",\"when\",\"when's\",\"where\",\"where's\",\"which\",\"while\",\"who\",\n",
        "\"who's\",\"whom\",\"why\",\"why's\",\"with\",\"won't\",\"would\",\"wouldn't\",\"you\",\"you'd\",\"you'll\",\n",
        "\"you're\",\"you've\",\"your\",\"yours\",\"yourself\",\"yourselves\"]\n",
        "\n",
        "def read_file(file,file_path):\n",
        "    fileHandler = codecs.open(file_path+\"/\" + file,'rU','latin-1')\n",
        "    Findwords = re.findall('[A-Za-z0-9\\']+', fileHandler.read())\n",
        "    allwords = list()\n",
        "    for word in Findwords:\n",
        "        word = word.lower()\n",
        "        allwords+=[word]\n",
        "    fileHandler.close()    \n",
        "    return allwords\n",
        "    \n",
        "def GetWordListsAndNumberOffiles(file_path):\n",
        "    wordList = list()\n",
        "    NumberOfFiles = 0\n",
        "    for files in os.listdir(file_path):\n",
        "        if files.endswith(\".txt\"):\n",
        "            wordList += read_file(files,file_path)\n",
        "            NumberOfFiles+=1\n",
        "    return wordList, NumberOfFiles\n",
        "\n",
        "def initiliazeMatrix(row, column):\n",
        "    featureMatrix = [0] * row\n",
        "    for i in range(row):\n",
        "        featureMatrix[i] = [0] * column\n",
        "    return featureMatrix"
      ],
      "metadata": {
        "id": "2SpA3gtZ8twZ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = 'enron1/train'"
      ],
      "metadata": {
        "id": "rn3gaRxvv7LZ"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#location of the folder for ham & spam for train and test\n",
        "\n",
        "HamFolderPath = train_path + '/ham'\n",
        "SpamFolderPath = train_path + '/spam'\n",
        "    "
      ],
      "metadata": {
        "id": "zCYkwPEG6s7y"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find out all the words in ham folder and spam folder and find there counts "
      ],
      "metadata": {
        "id": "c5mJPi8PAtuP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NumberOfHam, NumberOfSpam = 0, 0\n",
        "WordListInham = []\n",
        "WordListInspam = []\n",
        "WordListInham,NumberOfHam = GetWordListsAndNumberOffiles(HamFolderPath)\n",
        "WordListInspam,NumberOfSpam = GetWordListsAndNumberOffiles(SpamFolderPath)"
      ],
      "metadata": {
        "id": "lsIZOV1fVLdo"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Find out P(ham) and P(spam), by calculating the number of ham/spam documents and total number of documents"
      ],
      "metadata": {
        "id": "B3UEYtGkBY80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def FindPHamOrSpam(HamOrSpam):\n",
        "    if HamOrSpam == \"spam\":\n",
        "        Pspam = NumberOfSpam/(NumberOfSpam + NumberOfHam)\n",
        "        return Pspam\n",
        "    else:\n",
        "        Pham = NumberOfHam/(NumberOfSpam + NumberOfHam)\n",
        "        return Pham"
      ],
      "metadata": {
        "id": "hCIBpidGBcJA"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After finding all the words in ham and spam files , we will find the distinct words and its count"
      ],
      "metadata": {
        "id": "PdZUXP5SBy4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HamDictionary = dict(collections.Counter(w.lower() for w in WordListInham))\n",
        "SpamDictionary = dict(collections.Counter(w.lower() for w in WordListInspam))"
      ],
      "metadata": {
        "id": "5eJ-JDohB0Cz"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "making bag of words for both ham and spam and further counting the count of each Distinct word in it"
      ],
      "metadata": {
        "id": "UNrCph0wB5-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bagOfWords = WordListInham + WordListInspam\n",
        "BagOfWordsDict = collections.Counter(bagOfWords)"
      ],
      "metadata": {
        "id": "SurWq1FIB6-0"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def UpdateCountOfMissingWords(AllWords,HamSpamWords):\n",
        "    for words in AllWords:\n",
        "        if words not in HamSpamWords:\n",
        "            HamSpamWords[words] = 0"
      ],
      "metadata": {
        "id": "Z3ZPviR8CDco"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting missing words in each Ham and Spam list and adding them and intializing their count= 0"
      ],
      "metadata": {
        "id": "PTGQXxVjCHAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UpdateCountOfMissingWords(BagOfWordsDict,HamDictionary)\n",
        "UpdateCountOfMissingWords(BagOfWordsDict,SpamDictionary)"
      ],
      "metadata": {
        "id": "MFXHRbH6CH0j"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ProbOfHamWords = dict()\n",
        "ProbOfSpamWords = dict()"
      ],
      "metadata": {
        "id": "M5_4_DQsCN8o"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FindProbabilityOfWord(classifier,removestopwords):\n",
        "    Counter = 0\n",
        "    if(removestopwords ==1):\n",
        "            for word in stop_words:\n",
        "                if word in HamDictionary:\n",
        "                    del HamDictionary[word]\n",
        "                if word in SpamDictionary:\n",
        "                    del SpamDictionary[word]\n",
        "                if word in BagOfWordsDict:\n",
        "                    del BagOfWordsDict[word]                    \n",
        "    if classifier == \"ham\":\n",
        "        for word in HamDictionary:\n",
        "            Counter += (HamDictionary[word] + 1)\n",
        "        for word in HamDictionary:\n",
        "            ProbOfHamWords[word] = math.log((HamDictionary[word] + 1)/Counter ,2)\n",
        "    elif classifier == \"spam\":\n",
        "        for word in SpamDictionary:\n",
        "            Counter += (SpamDictionary[word] + 1)\n",
        "        for word in SpamDictionary:\n",
        "            ProbOfSpamWords[word] = math.log((SpamDictionary[word] + 1)/Counter ,2) "
      ],
      "metadata": {
        "id": "nWsVjF1kCPkw"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "caluculating probability for each word in ham and Spam folders "
      ],
      "metadata": {
        "id": "SO_DiXmpCVZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FindProbabilityOfWord(\"ham\",0)\n",
        "FindProbabilityOfWord(\"spam\",0) "
      ],
      "metadata": {
        "id": "-2w9FIQcCWXZ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally classify the emails as ham or spam   "
      ],
      "metadata": {
        "id": "0wb7mAYmCikz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def PredictHamOrSpam(pathToFile, classifier):\n",
        "    ProbabilityOfHam = 0 \n",
        "    ProbabilityOfSpam = 0 \n",
        "    InCorrectlyClassified = 0\n",
        "    NumberOfFiles = 0\n",
        "                   \n",
        "    if classifier == \"spam\":\n",
        "        for fileName in os.listdir(pathToFile):\n",
        "            words =read_file(fileName,pathToFile)\n",
        "            #find actual P(ham) and P(spam) i.e. (number of ham documents / Total no of documents)\n",
        "            ProbabilityOfHam = math.log(FindPHamOrSpam(\"ham\"),2)\n",
        "            ProbabilityOfSpam = math.log(FindPHamOrSpam(\"spam\"),2)\n",
        "            #log(P(ham|bodyText)) = log(P(ham)) + log(P(word1|ham)) + log(P(word2|ham)) + .... \n",
        "            for word in words:\n",
        "                if word in ProbOfHamWords:\n",
        "                    ProbabilityOfHam += ProbOfHamWords[word]\n",
        "                if word in ProbOfSpamWords:\n",
        "                    ProbabilityOfSpam += ProbOfSpamWords[word]\n",
        "            NumberOfFiles +=1\n",
        "            if(ProbabilityOfHam >= ProbabilityOfSpam):\n",
        "                InCorrectlyClassified+=1\n",
        "    if classifier == \"ham\":\n",
        "        for fileName in os.listdir(pathToFile):\n",
        "            words =read_file(fileName,pathToFile)\n",
        "            #find actual P(ham) and P(spam) i.e. (number of ham documents / Total no of documents)\n",
        "            ProbabilityOfHam = math.log(FindPHamOrSpam(\"ham\"),2)\n",
        "            ProbabilityOfSpam = math.log(FindPHamOrSpam(\"spam\"),2)\n",
        "            #log(P(ham|bodyText)) = log(P(ham)) + log(P(word1|ham)) + log(P(word2|ham)) + ....            \n",
        "            for word in words:\n",
        "                if word in ProbOfHamWords:\n",
        "                    ProbabilityOfHam += ProbOfHamWords[word]\n",
        "                if word in ProbOfSpamWords:\n",
        "                    ProbabilityOfSpam += ProbOfSpamWords[word]\n",
        "            NumberOfFiles +=1\n",
        "            if(ProbabilityOfHam <= ProbabilityOfSpam):\n",
        "                InCorrectlyClassified+=1\n",
        "    return InCorrectlyClassified,NumberOfFiles \n",
        "\n",
        "print(\"Executing Naive Bayes with stop words for Ham & Spam test emails :\")  \n"
      ],
      "metadata": {
        "id": "B-Mvnrg4CjvR",
        "outputId": "9f4dca3d-9764-44d2-a3ba-f6e22ce03632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing Naive Bayes with stop words for Ham & Spam test emails :\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = 'enron1/test'"
      ],
      "metadata": {
        "id": "spN4TuhIDWKC"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HamTestPath = test_path + '/ham'\n",
        "SpamTestPath = test_path + '/spam'        \n",
        "IncorrectlyClassifiedHam,TotalHamEmails = PredictHamOrSpam(HamTestPath, \"ham\")\n",
        "IncorrectlyClassifiedSpam,TotalSpamEmails = PredictHamOrSpam(SpamTestPath,\"spam\")\n",
        "AccuracyOfHamClassification = round(((TotalHamEmails - IncorrectlyClassifiedHam )/(TotalHamEmails ))*100,2)\n",
        "AccuracyOfSpamClassification = round(((TotalSpamEmails -  IncorrectlyClassifiedSpam )/(TotalSpamEmails))*100,2)\n",
        "AllEmailClassified = TotalHamEmails + TotalSpamEmails\n",
        "TotalIncorrectClassified = IncorrectlyClassifiedHam + IncorrectlyClassifiedSpam\n",
        "OverAllAccuracy = round(((AllEmailClassified  - TotalIncorrectClassified )/AllEmailClassified)*100,2)"
      ],
      "metadata": {
        "id": "IHOTgHjKDCVY"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTotal number of files: \", AllEmailClassified)\n",
        "print(\"\\nCalculating Accuracy over Ham Emails\")\n",
        "print(\"Total number of Ham Emails: \", TotalHamEmails)\n",
        "print(\"Number of Emails Classified as Ham: \", TotalHamEmails - IncorrectlyClassifiedHam)\n",
        "print(\"Number of Emails Classified as Spam: \",IncorrectlyClassifiedHam)\n",
        "print(\"\\nNaive Bayes Accuracy For Ham Emails Classification:\" + str(AccuracyOfHamClassification) + \"%\")"
      ],
      "metadata": {
        "id": "2mgLje5aNnpU",
        "outputId": "e1b4180b-4cea-4cb4-9425-492f70b93c36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of files:  456\n",
            "\n",
            "Calculating Accuracy over Ham Emails\n",
            "Total number of Ham Emails:  307\n",
            "Number of Emails Classified as Ham:  300\n",
            "Number of Emails Classified as Spam:  7\n",
            "\n",
            "Naive Bayes Accuracy For Ham Emails Classification:97.72%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCalculating Accuracy over Spam Emails\")\n",
        "print(\"Total number of Spam Emails: \", TotalSpamEmails)\n",
        "print(\"Number of Emails Classified as Spam: \", TotalSpamEmails - IncorrectlyClassifiedSpam)\n",
        "print(\"Number of Emails Classified as Ham: \",IncorrectlyClassifiedSpam)\n",
        "print(\"\\nNaive Bayes Accuracy For Spam Emails Classification: \" + str(AccuracyOfSpamClassification) + \"%\") "
      ],
      "metadata": {
        "id": "kLaTw4bENorN",
        "outputId": "03c64798-999a-48ce-a4f1-71cc1957ced0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating Accuracy over Spam Emails\n",
            "Total number of Spam Emails:  149\n",
            "Number of Emails Classified as Spam:  127\n",
            "Number of Emails Classified as Ham:  22\n",
            "\n",
            "Naive Bayes Accuracy For Spam Emails Classification: 85.23%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNaive Bayes Total accuracy for Test Emails: \" + str(OverAllAccuracy) + \"%\")\n",
        "\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "tYoOoeGhNq7U",
        "outputId": "10d20c3b-be2e-4657-e35e-fddba159b99f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Naive Bayes Total accuracy for Test Emails: 93.64%\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Executing Naive Bayes after removing stop words\")\n",
        "FindProbabilityOfWord(\"ham\",1)\n",
        "FindProbabilityOfWord(\"spam\",1) "
      ],
      "metadata": {
        "id": "Z3zvC10HNwMu",
        "outputId": "0171434e-70d6-4e07-98d3-96763277ff4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Executing Naive Bayes after removing stop words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IncorrectlyClassifiedHam,TotalHamEmails = PredictHamOrSpam(HamTestPath, \"ham\")\n",
        "IncorrectlyClassifiedSpam,TotalSpamEmails = PredictHamOrSpam(SpamTestPath,\"spam\")\n",
        "AccuracyOfHamClassification = round(((TotalHamEmails - IncorrectlyClassifiedHam )/(TotalHamEmails ))*100,2)\n",
        "AccuracyOfSpamClassification = round(((TotalSpamEmails -  IncorrectlyClassifiedSpam )/(TotalSpamEmails))*100,2)\n",
        "AllEmailClassified = TotalHamEmails + TotalSpamEmails\n",
        "TotalIncorrectClassified = IncorrectlyClassifiedHam + IncorrectlyClassifiedSpam\n",
        "OverAllAccuracy = round(((AllEmailClassified  - TotalIncorrectClassified )/AllEmailClassified)*100,2)"
      ],
      "metadata": {
        "id": "EjMe5VLEN0BS"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTotal number of files: \", AllEmailClassified)\n",
        "print(\"\\nCalculating Accuracy over Ham Emails\")\n",
        "print(\"Total number of Ham Emails: \", TotalHamEmails)\n",
        "print(\"Number of Emails Classified as Ham: \", TotalHamEmails - IncorrectlyClassifiedHam)\n",
        "print(\"Number of Emails Classified as Spam: \",IncorrectlyClassifiedHam)\n",
        "print(\"\\nNaive Bayes Accuracy For Ham Emails Classification:\" + str(AccuracyOfHamClassification) + \"%\")\n"
      ],
      "metadata": {
        "id": "8HpQ98cwN2vD",
        "outputId": "57414b45-9895-46a8-a9a4-e0dabb985db5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total number of files:  456\n",
            "\n",
            "Calculating Accuracy over Ham Emails\n",
            "Total number of Ham Emails:  307\n",
            "Number of Emails Classified as Ham:  301\n",
            "Number of Emails Classified as Spam:  6\n",
            "\n",
            "Naive Bayes Accuracy For Ham Emails Classification:98.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCalculating Accuracy over Spam Emails\")\n",
        "print(\"Total number of Spam Emails: \", TotalSpamEmails)\n",
        "print(\"Number of Emails Classified as Spam: \", TotalSpamEmails - IncorrectlyClassifiedSpam)\n",
        "print(\"Number of Emails Classified as Ham: \",IncorrectlyClassifiedSpam)\n",
        "print(\"\\nNaive Bayes Accuracy For Spam Emails Classification: \" + str(AccuracyOfSpamClassification) + \"%\")"
      ],
      "metadata": {
        "id": "87L0MS7FN5Dq",
        "outputId": "45c84855-1444-485f-b260-499b0c341aad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating Accuracy over Spam Emails\n",
            "Total number of Spam Emails:  149\n",
            "Number of Emails Classified as Spam:  122\n",
            "Number of Emails Classified as Ham:  27\n",
            "\n",
            "Naive Bayes Accuracy For Spam Emails Classification: 81.88%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNaive Bayes Total accuracy for Test Emails: \" + str(OverAllAccuracy) + \"%\")\n",
        "\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "id": "Tu48bXHLN7Di",
        "outputId": "b4db1195-4ec4-4439-e281-133376e92477",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Naive Bayes Total accuracy for Test Emails: 92.76%\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}